{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import concatenate\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryString</th>\n",
       "      <th>PredictedLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs1513 c# } expected</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs2001 c# source file could not be found.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs1001 c# identifier expected</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ide0055 c# fix formatting</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs7036 c# there is no argument given that corr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         QueryString  PredictedLabel\n",
       "0                               cs1513 c# } expected           False\n",
       "1          cs2001 c# source file could not be found.           False\n",
       "2                      cs1001 c# identifier expected           False\n",
       "3                          ide0055 c# fix formatting           False\n",
       "4  cs7036 c# there is no argument given that corr...           False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('~/Desktop/716/javaperformance/c_sharp.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictedLabel\n",
       "False    66.705882\n",
       "True     16.546422\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"len\"] = [len(text) for text in data[\"QueryString\"].values]\n",
    "data.groupby(\"PredictedLabel\")[\"len\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryString</th>\n",
       "      <th>PredictedLabel</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs1513 c# } expected</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs2001 c# source file could not be found.</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs1001 c# identifier expected</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ide0055 c# fix formatting</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs7036 c# there is no argument given that corr...</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         QueryString  PredictedLabel  len\n",
       "0                               cs1513 c# } expected           False   20\n",
       "1          cs2001 c# source file could not be found.           False   41\n",
       "2                      cs1001 c# identifier expected           False   29\n",
       "3                          ide0055 c# fix formatting           False   25\n",
       "4  cs7036 c# there is no argument given that corr...           False   89"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    \n",
    "    lemma = WordNetLemmatizer()\n",
    "    stp = stopwords.words('english')\n",
    "    \n",
    "    text = re.sub(\"[^a-zA-Z0-9#]\",\" \",text)\n",
    "    text = text.lower()\n",
    "\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    \n",
    "    text = [word for word in text if word not in stp]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs1513 c # expected\n"
     ]
    }
   ],
   "source": [
    "cleanedText = []\n",
    "for text in data[\"QueryString\"]:   \n",
    "    cleanedText.append(cleanText(text))\n",
    "print(cleanedText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     4039\n",
       "False     935\n",
       "Name: PredictedLabel, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PredictedLabel\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4974,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"PredictedLabel\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4974, 1990)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(cleanedText).toarray()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([9885059,     711,    1722,    1680,    1609,    1805,    1911,\n",
      "          1494,     794,    1475], dtype=int64), array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]))\n"
     ]
    }
   ],
   "source": [
    "print(np.histogram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "X_train_lab, X_test_unlab, y_train_lab, y_test_unlab = train_test_split(x_train, y_train, test_size=0.50, random_state=1, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier = XGBClassifier(objective= 'reg:squaredlogerror', use_label_encoder=False)\n",
    "#classifier = SVC()\n",
    "classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = classifier.predict(x_test)\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print('Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = LogisticRegression()\n",
    "#model = SVC()\n",
    "#model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100)\n",
    "#model.fit(X_train_lab, y_train_lab)\n",
    "LogisticRegression = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yhat = model.predict(x_test)\n",
    "\n",
    "#score = accuracy_score(y_test, yhat)\n",
    "#print('Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.025\n"
     ]
    }
   ],
   "source": [
    "nolabel = [-1 for _ in range(len(y_test_unlab))]\n",
    "\n",
    "y_train_mixed = concatenate((y_train_lab, nolabel))\n",
    "\n",
    "model = LabelPropagation()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "yhat = model.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_test, yhat)\n",
    "\n",
    "print('Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_labels = model.transduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.431\n"
     ]
    }
   ],
   "source": [
    "#model2 = SVC()\n",
    "model2 = LogisticRegression\n",
    "model2.fit(x_train, tran_labels)\n",
    "\n",
    "y_hat = model2.predict(x_test)\n",
    "score2 = accuracy_score(y_test, y_hat)\n",
    "print('Accuracy: %.3f' % (score2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test data: 0.075687\n",
      "RMSE test data: 0.52451\n",
      "R2 test data: 0.46559\n",
      "[[ 198   57]\n",
      " [  56 1182]]\n",
      "198\n",
      "57\n",
      "56\n",
      "1182\n",
      "Accuracy =  0.9243134628265238\n",
      "Precision =  0.7764705882352941\n",
      "Recall =  0.7795275590551181\n",
      "f1score =  0.7779960707269156\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_hat.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MSE test data: {:.5}'.format(test_mse))\n",
    "print('RMSE test data: {:.5}'.format(\n",
    "    np.sqrt(np.sqrt(np.absolute(test_mse)))))\n",
    "print('R2 test data: {:.5}'.format(\n",
    "    r2_score(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)\n",
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "print('Accuracy = ',accuracy)\n",
    "\n",
    "Precision = (TP)/(TP+FP)\n",
    "print('Precision = ',Precision)\n",
    "\n",
    "Recall = (TP)/(TP+FN)\n",
    "print('Recall = ',Recall)\n",
    "\n",
    "f1score = 2*(Recall*Precision)/(Recall+Precision)\n",
    "print('f1score = ',f1score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other single classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.489\n"
     ]
    }
   ],
   "source": [
    "model3 = SGDClassifier()\n",
    "model3.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "y_hat3 = model3.predict(x_test)\n",
    "score3 = accuracy_score(y_test, y_hat3)\n",
    "print('Accuracy: %.3f' % (score3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test data: 0.095111\n",
      "RMSE test data: 0.55534\n",
      "R2 test data: 0.32844\n",
      "[[ 158   97]\n",
      " [  45 1193]]\n",
      "158\n",
      "97\n",
      "45\n",
      "1193\n",
      "Accuracy =  0.9048894842598795\n",
      "Precision =  0.6196078431372549\n",
      "Recall =  0.7783251231527094\n",
      "f1score =  0.6899563318777293\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_hat3.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MSE test data: {:.5}'.format(test_mse))\n",
    "print('RMSE test data: {:.5}'.format(\n",
    "    np.sqrt(np.sqrt(np.absolute(test_mse)))))\n",
    "print('R2 test data: {:.5}'.format(\n",
    "    r2_score(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)\n",
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "print('Accuracy = ',accuracy)\n",
    "\n",
    "Precision = (TP)/(TP+FP)\n",
    "print('Precision = ',Precision)\n",
    "\n",
    "Recall = (TP)/(TP+FN)\n",
    "print('Recall = ',Recall)\n",
    "\n",
    "f1score = 2*(Recall*Precision)/(Recall+Precision)\n",
    "print('f1score = ',f1score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.355\n"
     ]
    }
   ],
   "source": [
    "model4 = XGBClassifier(use_label_encoder=False, objective= 'reg:squaredlogerror')\n",
    "model4.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "y_hat4 = model4.predict(x_test)\n",
    "score4 = accuracy_score(y_test, y_hat4)\n",
    "print('Accuracy: %.3f' % (score4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test data: 0.09645\n",
      "RMSE test data: 0.55728\n",
      "R2 test data: 0.31898\n",
      "[[ 169   86]\n",
      " [  58 1180]]\n",
      "169\n",
      "86\n",
      "58\n",
      "1180\n",
      "Accuracy =  0.9035498995311454\n",
      "Precision =  0.6627450980392157\n",
      "Recall =  0.7444933920704846\n",
      "f1score =  0.7012448132780082\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_hat4.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MSE test data: {:.5}'.format(test_mse))\n",
    "print('RMSE test data: {:.5}'.format(\n",
    "    np.sqrt(np.sqrt(np.absolute(test_mse)))))\n",
    "print('R2 test data: {:.5}'.format(\n",
    "    r2_score(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)\n",
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "print('Accuracy = ',accuracy)\n",
    "\n",
    "Precision = (TP)/(TP+FP)\n",
    "print('Precision = ',Precision)\n",
    "\n",
    "Recall = (TP)/(TP+FN)\n",
    "print('Recall = ',Recall)\n",
    "\n",
    "f1score = 2*(Recall*Precision)/(Recall+Precision)\n",
    "print('f1score = ',f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model5 = LogisticRegression()\n",
    "model5.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "y_hat5 = model5.predict(x_test)\n",
    "score5 = accuracy_score(y_test, y_hat5)\n",
    "print('Accuracy: %.3f' % (score5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test data: 0.11186\n",
      "RMSE test data: 0.57831\n",
      "R2 test data: 0.2102\n",
      "[[  93  162]\n",
      " [   5 1233]]\n",
      "93\n",
      "162\n",
      "5\n",
      "1233\n",
      "Accuracy =  0.8881446751507033\n",
      "Precision =  0.36470588235294116\n",
      "Recall =  0.9489795918367347\n",
      "f1score =  0.5269121813031161\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_hat5.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MSE test data: {:.5}'.format(test_mse))\n",
    "print('RMSE test data: {:.5}'.format(\n",
    "    np.sqrt(np.sqrt(np.absolute(test_mse)))))\n",
    "print('R2 test data: {:.5}'.format(\n",
    "    r2_score(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)\n",
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "print('Accuracy = ',accuracy)\n",
    "\n",
    "Precision = (TP)/(TP+FP)\n",
    "print('Precision = ',Precision)\n",
    "\n",
    "Recall = (TP)/(TP+FN)\n",
    "print('Recall = ',Recall)\n",
    "\n",
    "f1score = 2*(Recall*Precision)/(Recall+Precision)\n",
    "print('f1score = ',f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.484\n"
     ]
    }
   ],
   "source": [
    "model7 = MultinomialNB()\n",
    "model7.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "y_hat7 = model7.predict(x_test)\n",
    "score7 = accuracy_score(y_test, y_hat7)\n",
    "print('Accuracy: %.3f' % (score7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test data: 0.10516\n",
      "RMSE test data: 0.56946\n",
      "R2 test data: 0.2575\n",
      "[[ 109  146]\n",
      " [  11 1227]]\n",
      "109\n",
      "146\n",
      "11\n",
      "1227\n",
      "Accuracy =  0.8948425987943738\n",
      "Precision =  0.42745098039215684\n",
      "Recall =  0.9083333333333333\n",
      "f1score =  0.5813333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_hat7.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MSE test data: {:.5}'.format(test_mse))\n",
    "print('RMSE test data: {:.5}'.format(\n",
    "    np.sqrt(np.sqrt(np.absolute(test_mse)))))\n",
    "print('R2 test data: {:.5}'.format(\n",
    "    r2_score(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)\n",
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "print('Accuracy = ',accuracy)\n",
    "\n",
    "Precision = (TP)/(TP+FP)\n",
    "print('Precision = ',Precision)\n",
    "\n",
    "Recall = (TP)/(TP+FN)\n",
    "print('Recall = ',Recall)\n",
    "\n",
    "f1score = 2*(Recall*Precision)/(Recall+Precision)\n",
    "print('f1score = ',f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.958\n"
     ]
    }
   ],
   "source": [
    "model8 = DecisionTreeClassifier()\n",
    "model8.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "y_hat8 = model8.predict(x_test)\n",
    "score8 = accuracy_score(y_test, y_hat8)\n",
    "print('Accuracy: %.3f' % (score8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test data: 0.090422\n",
      "RMSE test data: 0.54836\n",
      "R2 test data: 0.36154\n",
      "[[ 191   64]\n",
      " [  71 1167]]\n",
      "191\n",
      "64\n",
      "71\n",
      "1167\n",
      "Accuracy =  0.9095780308104487\n",
      "Precision =  0.7490196078431373\n",
      "Recall =  0.7290076335877863\n",
      "f1score =  0.7388781431334622\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_hat8.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MSE test data: {:.5}'.format(test_mse))\n",
    "print('RMSE test data: {:.5}'.format(\n",
    "    np.sqrt(np.sqrt(np.absolute(test_mse)))))\n",
    "print('R2 test data: {:.5}'.format(\n",
    "    r2_score(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)\n",
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "print('Accuracy = ',accuracy)\n",
    "\n",
    "Precision = (TP)/(TP+FP)\n",
    "print('Precision = ',Precision)\n",
    "\n",
    "Recall = (TP)/(TP+FN)\n",
    "print('Recall = ',Recall)\n",
    "\n",
    "f1score = 2*(Recall*Precision)/(Recall+Precision)\n",
    "print('f1score = ',f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
